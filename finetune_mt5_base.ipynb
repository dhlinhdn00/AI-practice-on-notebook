{"cells":[{"cell_type":"code","source":["! pip install transformers[torch] evaluate torch rouge-score nltk datasets accelerate sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OszU2WyuDd4P","executionInfo":{"status":"ok","timestamp":1718231653616,"user_tz":-420,"elapsed":66887,"user":{"displayName":"Ho√†i Linh ƒê√†o","userId":"06427991247119097271"}},"outputId":"86a73cb6-d8af-45d7-9e50-1edf2064f5dc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Collecting evaluate\n","  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Collecting datasets\n","  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate\n","  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n","Collecting xxhash (from evaluate)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting requests (from transformers[torch])\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=36d90b6633261ef5b3902795826b64f2010efafecc9188cba6b527561a0d669f\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: xxhash, requests, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, rouge-score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, evaluate, accelerate\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.31.0 datasets-2.19.2 dill-0.3.8 evaluate-0.4.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 requests-2.32.3 rouge-score-0.1.2 xxhash-3.4.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bWGVLlwfJ9nd","executionInfo":{"status":"ok","timestamp":1718231682182,"user_tz":-420,"elapsed":28576,"user":{"displayName":"Ho√†i Linh ƒê√†o","userId":"06427991247119097271"}},"outputId":"e5d02bce-4da0-480e-b791-e53cece91d5c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3VUJXxiTDa3d","executionInfo":{"status":"ok","timestamp":1718231691964,"user_tz":-420,"elapsed":9790,"user":{"displayName":"Ho√†i Linh ƒê√†o","userId":"06427991247119097271"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, Dataset\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    DataCollatorForSeq2Seq,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer\n",")\n","from datasets import load_dataset, DatasetDict\n","from sklearn.model_selection import train_test_split\n","from nltk.tokenize import RegexpTokenizer\n","from torch.utils.data import Subset\n","import evaluate\n","import os\n","import pandas as pd\n","import numpy as np\n","import csv"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"4nCRdAXLDa3f","executionInfo":{"status":"ok","timestamp":1718231691964,"user_tz":-420,"elapsed":5,"user":{"displayName":"Ho√†i Linh ƒê√†o","userId":"06427991247119097271"}}},"outputs":[],"source":["import os\n","os.environ['NCCL_P2P_DISABLE'] = '1'\n","os.environ['NCCL_IB_DISABLE'] = '1'"]},{"cell_type":"markdown","metadata":{"id":"OXdv1YaQDa3g"},"source":["#**CHECK DATA: Xlsum**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qF2FhWlWDa3g"},"outputs":[],"source":["# https://huggingface.co/datasets/csebuetnlp/xlsum/viewer/japanese"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"aYucHHi8Da3h","outputId":"6f2628af-cafb-489d-ca26-1326a9a73ee1","colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["1cf1455a73444e5eb3d1c3121a10d51b","d6614e6c3170409aaba5b95454719a34","4257aa2e4c1b45bb95847016e8e800ff","01d44f733dc64e33bb44ea0d8c7ac3fe","1811f10e28604e90bf695672b8caeba6","2bce50c532e047dca91dd2adc632d920","b6c6abbc5b9c4aecac0e7b0a2ffe6f7d","0fabedc1808c4e28b992234fb99963ef","6491d7f89e724f0e9545412a3dbf4e02","c45d0d21fd7d42cf86ab02c90340204a","cde91f5a4f4a4a8488d61ec949de92db","2ee99f7892cb4fa2a4db015f40023790","f0056d0a29cf4982b850babf1e7b0220","7b9b630d9bea453f854ca476d02276e6","8a07932f6c7745b295bd8f646811a83b","c81a75b44acb4974a1304a4a99f64de7","4bff5aa092144d29b35878ff82f5fa44","f0396c376eb74545b90740696a44cc53","693c5b04a17f4760911a5a247444f2ca","05f6646e646647adb856865493ca5bef","0cd0372a52904d47ac3edc816771a328","4df77d52155146888201922a500185e0","21f241cfea3c43cab8039f9d1a00b09f","f9f292a70a3b420e8b06a287983c2a12","d475611e5ae54004b39471566d15fe9a","c4ab2bc6a59b4241802cf0c73d0bf206","e8dcf9b4e88b4c1c854e594d673087b0","a970946bd3414fa6816c7aadcd488e14","fcbba861ba1949ae8648849907cf3609","7220410a6f234fe78a5ec0b91c0f49f8","50a8156bd3d544b48f3ed0a6b891cb17","b3354094bcd24d46809ef99c573d9c79","64cef3f116bf4c05b15c6660c9fc63e5","ce4a6a1415144a84be431675e1d317d2","c4065af0cca74684bb6983da03d3db64","f65fe8852a2b401b8bebce7e48f9d364","c3b7ef83f11f41d288918238924e13c0","6028e1d34bab4f5eade76ad986174a0a","399701a5b9db478bab74f93c07405b22","c4368051b8734fdb89d50afe72c7efdd","2f469bbb714245e7bdf3ffaadc06f61f","63f31f5f0c384ce5b3448300d5412d3e","60401a40a61646b19b06fd6e2d963e70","922c02e0413b44218acac27a9fe4e7ad","4c43ef7987f64a5a97581b8b718f8dd1","80d71f5ec03449eaa2e49f569cc93a8d","239cb5706351413fa4a15ed42d022348","2754936e9ed74dac8d7d53e5a61f9d7b","249cf1379f864d34b0ee9f79b3966a47","48a32d0550244fc0a0398fe4e208bafe","27ac1b2b91314eaa84a6c0e9a361749c","550c8051bbf044fba2c10dc5e0ce1dae","5b752d8402d7435e91bcc806e969eb43","8bae4635c7754fe1bdaf11e46141d570","b87a05de18534c9da06d812ef230a938","edf7ae9bdc1a4fdcbddd88ef6b6b996b","175f8038a1294f52828c9327e0ba0ec8","05391904ef58406b9a6afc230c649e6e","6e3eb2770ea34144a7170fd24084ff8c","91c95f3254744db99d39ab5c78415af1","998c9f5c4449462eb0b6a74f68c859c6","2daa6fff41ea4beabaec587d0528609c","1f7e14863ad046eaa70bbdd9e5243c5c","e92fbb466a9740bd9bdaa354acd858b3","0e7dab09b9b144beaf1c1063897641b6","c8623e401cf645e091ef196820def42c"]},"executionInfo":{"status":"ok","timestamp":1718231708860,"user_tz":-420,"elapsed":16900,"user":{"displayName":"Ho√†i Linh ƒê√†o","userId":"06427991247119097271"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/21.1M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cf1455a73444e5eb3d1c3121a10d51b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/2.54M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ee99f7892cb4fa2a4db015f40023790"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21f241cfea3c43cab8039f9d1a00b09f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/7113 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4a6a1415144a84be431675e1d317d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/889 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c43ef7987f64a5a97581b8b718f8dd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/889 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edf7ae9bdc1a4fdcbddd88ef6b6b996b"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'url', 'title', 'summary', 'text'],\n","        num_rows: 7113\n","    })\n","    test: Dataset({\n","        features: ['id', 'url', 'title', 'summary', 'text'],\n","        num_rows: 889\n","    })\n","    validation: Dataset({\n","        features: ['id', 'url', 'title', 'summary', 'text'],\n","        num_rows: 889\n","    })\n","})"]},"metadata":{},"execution_count":5}],"source":["ds = load_dataset(\"csebuetnlp/xlsum\", \"japanese\")\n","ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFZ2jw2HDa3h","outputId":"8d63b686-ec63-491c-e1fb-92e6b79fbe41"},"outputs":[{"data":{"text/plain":["{'id': '44789754',\n"," 'url': 'https://www.bbc.com/japanese/44789754',\n"," 'title': '„Çø„Ç§Ê¥ûÁ™ü„Åã„ÇâÂ∞ëÂπ¥„Å®„Ç≥„Éº„ÉÅ„ÄÅÂÖ®Âì°ÁÑ°‰∫ãÊïëÂá∫',\n"," 'summary': '„Çø„Ç§ÂåóÈÉ®„ÅÆ„Çø„É†„É´„Ç¢„É≥Ê¥ûÁ™ü„Åß10Êó•Â§ú„ÄÅ‰∏≠„Å´Èñâ„ÅòËæº„ÇÅ„Çâ„Çå„Å¶„ÅÑ„ÅüÂ∞ëÂπ¥12‰∫∫„Å®„Çµ„ÉÉ„Ç´„Éº„Éª„Ç≥„Éº„ÉÅ„ÅÆË®à13‰∫∫„ÅÆ„ÅÜ„Å°„ÄÅÊúÄÂæå„ÅÆÂ∞ëÂπ¥4‰∫∫„Å®„Ç≥„Éº„ÉÅ„ÅåÊ∞¥Ë∑Ø„ÇíÊΩú„ÇäÁÑ°‰∫ãËÑ±Âá∫„Åó„Åü„ÄÇ„Åù„ÅÆÁ¥Ñ3ÊôÇÈñìÂæå„Å´„ÅØ„ÄÅÊ¥ûÁ™üÂÜÖ„ÅßÂ∞ëÂπ¥„Åü„Å°„Å®Áïô„Åæ„Å£„Å¶„ÅÑ„ÅüÊµ∑Ëªç„ÉÄ„Ç§„Éê„Éº3‰∫∫„Å®ÂåªÂ∏´„ÇÇÁîüÈÇÑ„Åó„Åü„ÄÇ17Êó•Èñì„ÇÇÊ¥ûÁ™üÂÜÖ„Å´„ÅÑ„Åü13‰∫∫„ÅÆÊïëÂá∫„Å´„ÄÅ„Çø„Ç§ÂõΩÂÜÖÂ§ñ„ÅßÂ§ö„Åè„ÅÆ‰∫∫„ÅåÂÆâÂøÉ„Åó„ÄÅÂñú„Çì„Åß„ÅÑ„Çã„ÄÇ',\n"," 'text': 'ÊïëÂá∫‰ΩúÊà¶„ÅÆÈñì„ÄÅÊ¥ûÁ™üÂÜÖ„Å´Â∞ëÂπ¥„Åü„Å°„Å®Áïô„Åæ„Å£„Åü„Çø„Ç§Êµ∑Ëªç„ÅÆ„ÉÄ„Ç§„Éê„Éº„Å®ÂåªÂ∏´„ÇÇÊúÄÂæå„Å´ÁÑ°‰∫ãËÑ±Âá∫„Åó„Åü„ÄÇ4‰∫∫„ÅÆÂÜôÁúü„ÅØ10Êó•„ÄÅ„Çø„Ç§Êµ∑ËªçÁâπÊÆäÈÉ®Èöä„Åå„Éï„Çß„Ç§„Çπ„Éñ„ÉÉ„ÇØ„Å´Êé≤Ëºâ„Åó„Åü„ÇÇ„ÅÆ „Çø„Ç§Êµ∑ËªçÁâπÊÆäÈÉ®Èöä„ÅØ„Éï„Çß„Ç§„Çπ„Éñ„ÉÉ„ÇØ„Åß„ÄÅ„Äå„Åì„Çå„ÅØÂ•áË∑°„Å™„ÅÆ„ÅãÁßëÂ≠¶„Å™„ÅÆ„Åã„ÄÅ‰∏Ä‰Ωì‰Ωï„Å™„ÅÆ„Åã„Çà„Åè„Çè„Åã„Çâ„Å™„ÅÑ„ÄÇ„Äé„Ç§„Éé„Ç∑„Ç∑„Äè13‰∫∫„ÅØÂÖ®Âì°„ÄÅÊ¥ûÁ™ü„Åã„ÇâÂá∫„Åü„Äç„Å®ÊïëÂä©‰ΩúÊà¶„ÅÆÁµÇ‰∫Ü„ÇíÂ†±Âëä„Åó„Åü„ÄÇ„Äå„Ç§„Éé„Ç∑„Ç∑„ÄçÔºà„Çø„Ç§Ë™û„Åß„Äå„É†„Éº„Éë„ÄçÔºâ„ÅØÂ∞ëÂπ¥„Åü„Å°„ÅÆÊâÄÂ±û„Åô„Çã„Çµ„ÉÉ„Ç´„Éº„Éª„ÉÅ„Éº„É†„ÅÆÊÑõÁß∞„ÄÇ ÈÅ†Ë∂≥„Å´Âá∫„Åã„Åë„Åü11Ê≠≥„Åã„Çâ17Ê≠≥„ÅÆÂ∞ëÂπ¥„Åü„Å°„Å®25Ê≠≥„ÅÆ„Çµ„ÉÉ„Ç´„Éº„Éª„Ç≥„Éº„ÉÅ„ÅØ6Êúà23Êó•„ÄÅÂ§ßÈõ®„ÅßÂ¢óÊ∞¥„Åó„ÅüÊ¥ûÁ™ü„Åã„ÇâÂá∫„Çâ„Çå„Å™„Åè„Å™„Å£„Åü„ÄÇ„Çø„Ç§ÂÜÖÂ§ñ„Åã„ÇâÈõÜ„Åæ„Å£„Åü„ÉÄ„Ç§„Éê„ÉºÁ¥Ñ90‰∫∫„Å™„Å©„ÅåÊçúÁ¥¢„Å´ÂΩì„Åü„Çä„ÄÅËã±ÂõΩ‰∫∫„ÉÄ„Ç§„Éê„Éº2‰∫∫„Å´„Çà„Å£„Å¶7Êúà2Êó•Â§ú„Å´Áô∫Ë¶ã„Åï„Çå„Åü„ÄÇÂú∞ÂÖÉ„ÅÆ„ÉÅ„Çß„É≥„É©„Ç§ÁúåÁü•‰∫ã„ÇÑ„Çø„Ç§Êµ∑ËªçÁâπÊÆäÈÉ®Èöä„Åå‰∏≠ÂøÉ„Å®„Å™„Å£„ÅüÊïëÂä©Êú¨ÈÉ®„ÅØÂΩìÂàù„ÄÅÊ∞¥„ÅåÂºï„Åè„Åã„ÄÅ„ÅÇ„Çã„ÅÑ„ÅØÂ∞ëÂπ¥„Åü„Å°„ÅåÊΩúÊ∞¥ÊäÄË°ì„ÇíÁøíÂæó„Åô„Çã„Åæ„ÅßÊôÇÈñì„Çí„Åã„Åë„Å¶ËÑ±Âá∫„Åï„Åõ„Çã„Å§„ÇÇ„Çä„Å†„Å£„Åü„Åå„ÄÅÈõ®Â≠£„Å´„Çà„ÇãÊ∞¥‰Ωç‰∏äÊòá„Å®Ê¥ûÁ™üÂÜÖ„ÅÆÈÖ∏Á¥†‰Ωé‰∏ã„ÅÆÈÄ≤Ë°å„ÅåÊá∏Âøµ„Åï„Çå„ÄÅ8Êó•„Åã„Çâ3Êó•ÈÄ£Á∂ö„ÅÆÊïëÂá∫‰ΩúÊà¶„ÅåÊï¢Ë°å„Åï„Çå„Åü„ÄÇ Â∞ëÂπ¥„Åü„Å°„ÅÆËÑ±Âá∫ÊñπÊ≥ï „ÉÄ„Ç§„Éê„Éº„Åü„Å°„Å´ÂâçÂæå„ÇíÊîØ„Åà„Çâ„Çå„ÄÅÊ∞¥Ë∑ØÂÜÖ„Å´Âºµ„ÇäÂ∑°„Çâ„Åï„Çå„Åü„Ç¨„Ç§„Éâ„É≠„Éº„Éó„Çí„Åü„Å©„Çä„Å™„Åå„Çâ„ÄÅÊΩúÊ∞¥ÁµåÈ®ì„ÅÆ„Å™„ÅÑÂ∞ëÂπ¥„Åü„Å°„ÅØËÑ±Âá∫„Åó„Åü„ÄÇ8Êó•„Å´ÊúÄÂàù„ÅÆ4‰∫∫„ÄÅ9Êó•„Å´4‰∫∫„ÄÅ10Êó•„Å´ÊÆã„Çã5‰∫∫„ÅåËÑ±Âá∫„Åó„ÄÅ„Åü„Å†„Å°„Å´Ëøë„Åè„ÅÆ„ÉÅ„Çß„É≥„É©„Ç§Â∏ÇÂÜÖ„ÅÆÁóÖÈô¢„Å´Êê¨ÈÄÅ„Åï„Çå„Åü„ÄÇ2ÈÄ±Èñì‰ª•‰∏äÊ¥ûÁ™ü„Å´Èñâ„ÅòËæº„ÇÅ„Çâ„Çå„Å¶„ÅÑ„Åü„Åì„Å®„ÇíÊÄù„Åà„Å∞„ÄÅÂÖ®Âì°È©ö„Åè„Åª„Å©ÂøÉË∫´„Å®„ÇÇ„Å´ÂÖÉÊ∞ó„Å†„Å®„ÅÑ„ÅÜ„ÄÇ Â∞ëÂπ¥„Åü„Å°„Å®„Ç≥„Éº„ÉÅ„ÅØ„É¨„É≥„Éà„Ç≤„É≥„ÇÑË°ÄÊ∂≤Ê§úÊüª„Å™„Å©„ÇíÂèó„Åë„Åü„ÄÇÂ∞ë„Å™„Åè„Å®„ÇÇ7Êó•Èñì„ÅØ„ÄÅÁµåÈÅéË¶≥ÂØü„ÅÆ„Åü„ÇÅ„Å´ÂÖ•Èô¢„ÇíÁ∂ö„Åë„Çã„Å®„ÅÑ„ÅÜ„ÄÇ Ê¥ûÁ™üÂÜÖ„ÅÆÊ∞¥„ÇíÈ£≤„Åø„ÄÅÈ≥•„ÇÑ„Ç≥„Ç¶„É¢„É™„ÅÆÊéíÊ≥ÑÁâ©„Å´Êé•Ëß¶„Åó„ÅüÂèØËÉΩÊÄß„ÅÆ„ÅÇ„Çã13‰∫∫„ÅØ„ÄÅÁóÖÂéü‰Ωì„Å´ÊÑüÊüì„Åó„Å¶„ÅÑ„Çã„Åä„Åù„Çå„Åå„ÅÇ„Çã„Åü„ÇÅÈöîÈõ¢„Åï„Çå„Å¶„ÅÑ„Çã„ÄÇÂÆ∂Êóè„Å®„ÅØ„Ç¨„É©„ÇπË∂ä„Åó„Å´ÂÜç‰ºö„Åó„Åü„Å®„ÅÑ„ÅÜ„ÄÇ È£ü„ÅπÁâ©„ÅÆ„Åª„Å®„Çì„Å©„Å™„ÅÑÊ¥ûÁ™üÂÜÖ„Åß2ÈÄ±Èñì‰ª•‰∏ä„ÇíÈÅé„Åî„Åó„ÅüÂ∞ëÂπ¥„Åü„Å°„ÅØ‰ΩìÈáç„ÇíÂ§ßÂπÖ„Å´ËêΩ„Å®„Åó„ÄÅÁ©∫ËÖπ„ÇíË®¥„Åà„Å¶„ÅÑ„Åü„ÄÇÊïëÂá∫Âæå„ÅØÂ•ΩÁâ©„ÅÆË±öËÇâ„ÅÆ„ÅîÈ£Ø„ÇÑ„Éë„É≥„ÄÅ„ÉÅ„Éß„Ç≥„É¨„Éº„Éà„Å™„Å©„ÇíÂ∏åÊúõ„Åó„Åü„Åå„ÄÅ„Åó„Å∞„Çâ„Åè„ÅØÊµÅÂãïÈ£ü„ÅåÁ∂ö„Åè„Å®„ÅÑ„ÅÜ„ÄÇ „Åï„Çâ„Å´„ÄÅÂ§ñÁïå„ÅÆÂÖâ„Å´ÁõÆ„ÅåÊÖ£„Çå„Çã„Åæ„Åß„ÅÆÊï∞Êó•„ÅØ„ÄÅ„Çµ„É≥„Ç∞„É©„Çπ„Çí„Åã„Åë„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ Ôºú„Åä„Åô„Åô„ÇÅË®ò‰∫ãÔºû ÊïëÂá∫‰ΩúÊà¶„ÅåÁµÇ„Çè„Çã„Å®„ÄÅÊ¥ûÁ™ü„ÅÆÂá∫Âè£„Å´ÈõÜ„Åæ„Å£„ÅüÊïëÂä©Èñ¢‰øÇËÄÖ„Åã„ÇâÂ§ß„Åç„Å™Ê≠ìÂ£∞„Åå‰∏ä„Åå„Å£„Åü„ÄÇÂ±±„ÅÆ„Åµ„ÇÇ„Å®„Å´„ÅØ„ÄÅÂ∞ëÂπ¥„Åü„Å°„ÅåÊâÄÂ±û„Åô„Çã„Äå„É†„Éº„ÉëÔºà„Ç§„Éé„Ç∑„Ç∑Ôºâ„Äç„Çµ„ÉÉ„Ç´„Éº„ÉÅ„Éº„É†„ÅÆÈñ¢‰øÇËÄÖ„ÅÆÂÆ∂„Åå„ÅÇ„Çä„ÄÅ„Åù„Åì„Å´ÈõÜ„Åæ„Å£„Åü‰∫∫„Åü„Å°„ÇÇÁ¨ëÈ°î„ÅßÂè´„Çì„Å†„ÇäÊ≠ìÂ£∞„ÇíÊåô„Åí„Åü„Çä„Åó„Åü„ÄÇÁèæÂ†¥„Å´„ÅÑ„ÅüBBC„ÅÆ„Ç∏„Éß„Éä„Çµ„É≥„Éª„Éò„ÉÉ„ÉâË®òËÄÖ„ÅØ„ÄÅÂñú„Å∂‰∫∫„Åü„Å°„ÅØ„Äå„Å®„Å¶„ÇÇ„Çø„Ç§‰∫∫„Çâ„Åó„Åè„Å™„ÅÑÊßòÂ≠ê„Åß„Äç„Åï„Åã„Çì„Å´Êè°Êâã„Çí„Åó„Å¶Âõû„Å£„Å¶„ÅÑ„Åü„Å®‰ºù„Åà„Åü„ÄÇ Â∞ëÂπ¥„Åü„Å°„Å∏„ÅÆÁ≤æÁ•ûÁöÑÂΩ±Èüø„ÅØÔºü „Çø„Ç§Ê¥ûÁ™üÊïëÂä© „ÉÅ„Çß„É≥„É©„Ç§Â∏Ç„Åß„ÅØ„ÄÅÂÖ®Âì°ËÑ±Âá∫„ÅÆÁü•„Çâ„Åõ„Å´ÂæÄÊù•„ÅÆËªä„ÅØÊ¨°„ÄÖ„Å´„ÇØ„É©„ÇØ„Ç∑„Éß„É≥„ÇíÈ≥¥„Çâ„Åó„Å¶Âñú„Çì„Å†„ÄÇÂ≠ê‰æõ„Åü„Å°„ÇÑ„Ç≥„Éº„ÉÅ„ÅåÊê¨ÈÄÅ„Åï„Çå„ÅüÁóÖÈô¢„ÅÆÂ§ñ„Å´ÈõÜ„Åæ„Å£„Å¶„ÅÑ„Åü‰∫∫„Åü„Å°„ÅØ„ÄÅ‰∏ÄÊñâ„Å´ÊãçÊâã„Åó„Åü„ÄÇ „ÇΩ„Éº„Ç∑„É£„É´„É°„Éá„Ç£„Ç¢„Åß„ÅØ„Çø„Ç§‰∫∫„ÅÆÂ§ö„Åè„Åå„ÄÅ„Äå#Heroes(Ëã±ÈõÑÔºâ„Äç„ÄÅ„Äå #ThankyouÔºà„ÅÇ„Çä„Åå„Å®„ÅÜÔºâ„Äç„Å™„Å©„ÅÆ„Éè„ÉÉ„Ç∑„É•„Çø„Ç∞„Çí‰Ωø„Å£„Å¶„ÄÅ„Åù„Çå„Åû„Çå„Å´ÊÄù„ÅÑ„ÇíË°®Áèæ„Åó„Å¶„ÅÑ„Åü„ÄÇ 13‰∫∫„ÅØ2Êó•„ÄÅÊ¥ûÁ™üÂÜÖ„ÅÆÂ≤©Â†¥„Å´Ë∫´„ÇíÂØÑ„Åõ„Å¶„ÅÑ„Çã„Å®„Åì„Çç„ÇíÁô∫Ë¶ã„Åï„Çå„Åü„ÄÇ‰∏≠Â§Æ„ÅÆÂ∞ëÂπ¥„ÅØ„ÄÅ„Çµ„ÉÉ„Ç´„Éº„ÅÆ„Ç§„É≥„Ç∞„É©„É≥„Éâ‰ª£Ë°®„ÅÆ„Ç∑„É£„ÉÑ„ÇíÁùÄ„Å¶„ÅÑ„Çã„ÄÇÂÜôÁúü„ÅØ„Çø„Ç§Êµ∑Ëªç„Åå4Êó•„Å´ÂÖ¨Ë°®„Åó„Åü„Éì„Éá„Ç™„Çà„Çä „Çµ„ÉÉ„Ç´„ÉºÁïå„ÇÇÂ∞ëÂπ¥„Åü„Å°„Å®„Ç≥„Éº„ÉÅ„ÅÆÁÑ°‰∫ã„ÇíÂ§ß„ÅÑ„Å´Âñú„Å≥„ÄÅËã±„Éû„É≥„ÉÅ„Çß„Çπ„Çø„Éº„Éª„É¶„Éä„Ç§„ÉÜ„ÉÉ„Éâ„ÇÑ„Éù„É´„Éà„Ç¨„É´„ÅÆ„Éô„É≥„Éï„Ç£„Ç´„ÅåÂÖ®Âì°„ÇíË©¶Âêà„Å´ÊãõÂæÖ„Åó„Åü„ÄÇÂõΩÈöõ„Çµ„ÉÉ„Ç´„ÉºÈÄ£ÁõüÔºàFIFAÔºâ„ÇÇ„ÄÅÂ∞ëÂπ¥„Åü„Å°„Çí„É≠„Ç∑„Ç¢„ÅßÈñãÂÇ¨„Åï„Çå„Å¶„ÅÑ„Çã„ÉØ„Éº„É´„Éâ„Ç´„ÉÉ„Éó„ÅÆ15Êó•„Å´„ÅÇ„ÇãÊ±∫ÂãùÊà¶„Å´Êãõ„ÅÑ„Åü„Åå„ÄÅ„Åì„Çå„ÅØÂõûÂæ©„ÅåÈñì„Å´Âêà„Çè„Å™„ÅÑ„Å®„ÅÑ„ÅÜÁêÜÁî±„ÅßË¶ãÈÄÅ„Çâ„Çå„Åü„ÄÇ „ÉØ„Éº„É´„Éâ„Ç´„ÉÉ„Éó„ÅÆÊ∫ñÊ±∫Âãù„Å´ÂÇô„Åà„Çã„Ç§„É≥„Ç∞„É©„É≥„Éâ‰ª£Ë°®„ÅÆDF„Ç´„Ç§„É´„Éª„Ç¶„Ç©„Éº„Ç´„Éº„ÅØ„ÄÅ„Ç§„É≥„Ç∞„É©„É≥„Éâ„ÅÆ„É¶„Éã„Éï„Ç©„Éº„É†„ÇíÂ∞ëÂπ¥„Åü„Å°„Å´Ë¥à„Çä„Åü„ÅÑ„Å®„ÉÑ„Ç§„Éº„Éà„Åó„Åü„ÄÇÂ∞ëÂπ¥„ÅÆ1‰∫∫„ÅØÊ¥ûÁ™üÂÜÖ„Åß„ÄÅ„Ç§„É≥„Ç∞„É©„É≥„Éâ„ÅÆ„Ç∏„É£„Éº„Ç∏„Éº„ÇíÁùÄ„Å¶„ÅÑ„Åü„ÄÇ„Åô„Çã„Å®Ëã±Â§ñÂãôÁúÅ„ÅÆÂÖ¨Âºè„Ç¢„Ç´„Ç¶„É≥„Éà„Åå„Åì„Çå„Å´Âøú„Åà„Å¶„ÄÅ„Äå„ÇÑ„ÅÇ„ÄÅ„Ç´„Ç§„É´„ÄÇÈßê„Çø„Ç§Ëã±ÂõΩÂ§ß‰Ωø„Å®Ë©±„Çí„Åó„Åü„ÄÇ„Ç§„É≥„Ç∞„É©„É≥„Éâ„ÅÆ„Ç∑„É£„ÉÑ„ÇíÂãáÊï¢„Å™Â∞ëÂπ¥„Åü„Å°„Å´„ÄÅÂñú„Çì„Åß„ÄÅÁ¢∫ÂÆü„Å´Â±ä„Åë„Å¶„Åè„Çå„Çã„Åù„ÅÜ„Å†„Äç„Å®„ÉÑ„Ç§„Éº„Éà„Åó„Åü„ÄÇ ÁµåÈ®ìË±äÂØå„Å™„ÉÄ„Ç§„Éê„Éº„Å´„Å®„Å£„Å¶„ÇÇ„ÄÅÂ∞ëÂπ¥„Åü„Å°„ÅÆ„ÅÑ„ÇãÂ†¥ÊâÄ„Åæ„Åß„ÅÆÂæÄÂæ©„ÅØÈáçÂä¥ÂÉç„Å†„Å£„Åü„ÄÇÂÖÉ„Çø„Ç§Êµ∑ËªçÊΩúÊ∞¥Â£´„ÅÆ„Çµ„Éû„É≥„Éª„Ç∞„Éä„É≥„Åï„Çì„ÅØ6Êó•„ÄÅÂ∞ëÂπ¥„Åü„Å°„Å´Á©∫Ê∞ó„Éú„É≥„Éô„ÇíÈÅã„Å∂‰ªªÂãô„ÇíÊûú„Åü„Åó„Å¶Êàª„Çç„ÅÜ„Å®„Åó„Å¶„ÅÑ„Åü„Å®„Åì„Çç„ÄÅÈÖ∏Á¥†‰∏çË∂≥„ÅßÂëΩ„ÇíËêΩ„Å®„Åó„Åü„ÄÇ „ÉÄ„Ç§„Éê„Éº„Åü„Å°„ÅåÂá∫Âè£„Åæ„ÅßÂºµ„Å£„Åü„Ç¨„Ç§„Éâ„É≠„Éº„Éó„Çí„Åü„Å©„Çä„Å™„Åå„Çâ„ÄÅÂ∞ëÂπ¥„Åü„Å°„ÅØÂ†¥ÊâÄ„Å´„Çà„Å£„Å¶„ÄÅÊ≠©„ÅÑ„Åü„Çä„ÄÅÊ∞¥„ÅÆ‰∏≠„ÇíÊ≠©„ÅÑ„Åü„Çä„ÄÅÁôª„Å£„Åü„ÇäÊΩú„Å£„Åü„Çä„Åó„Å¶Â§ñ„Å´Âá∫„Åü„ÄÇ Â∞ëÂπ¥„Åü„Å°„ÅØ„ÄÅÈÄöÂ∏∏„ÅÆ„Éû„Çπ„ÇØ„Çà„Çä„ÇÇÂàùÂøÉËÄÖ„Å´ÈÅ©„Åó„ÅüÈ°îÈÉ®ÂÖ®‰Ωì„ÇíË¶Ü„ÅÜ„Éû„Çπ„ÇØ„Çí„Åã„Å∂„Å£„Åü„ÄÇÂ∞ëÂπ¥1‰∫∫„Å´„Å§„Åç2‰∫∫„ÅÆ„ÉÄ„Ç§„Éê„Éº„Åå‰ªò„Åç„ÄÅ„ÉÄ„Ç§„Éê„Éº„ÅåÂ∞ëÂπ¥„ÅÆÁ©∫Ê∞ó„Éú„É≥„Éô„ÇíÈÅã„Çì„Å†„ÄÇ ÊúÄ„ÇÇÂõ∞Èõ£„Å™„ÅÆ„ÅØ„ÄÅÊ¥ûÁ™ü„ÅÆ‰∏≠„Åª„Å©„Å´„ÅÇ„Çã„ÄåT„Ç∏„É£„É≥„ÇØ„Ç∑„Éß„É≥„Äç„Å®Âëº„Å∞„Çå„Å¶„ÅÑ„ÇãÂ†¥ÊâÄ„Åß„ÄÅ„ÅÇ„Åæ„Çä„Å´Áã≠„ÅÑ„Åü„ÇÅ„ÄÅ„ÉÄ„Ç§„Éê„Éº„ÅØÁ©∫Ê∞ó„Éú„É≥„Éô„ÇíÂ§ñ„Åó„Å¶ÈÄ≤„ÇÄÂøÖË¶Å„Åå„ÅÇ„Å£„Åü„ÄÇ T„Ç∏„É£„É≥„ÇØ„Ç∑„Éß„É≥„ÇíÊäú„Åë„Çã„Å®„ÄÅ„ÉÄ„Ç§„Éê„ÉºÈÅî„ÅÆÂü∫Âú∞„Å®„Å™„Å£„Å¶„ÅÑ„Çã„ÄåÁ¨¨3ÂÆ§„Äç„Åå„ÅÇ„Çä„ÄÅÂ∞ëÂπ¥„Åü„Å°„ÅØ„Åì„Åì„ÅßÂá∫Âè£„Å∏Âêë„Åã„ÅÜÂâç„Å´‰ºëÊÅØ„Åå„Å®„Çå„Åü„ÄÇ Â∞ëÂπ¥„Çâ„ÅÆÊïëÂá∫ÁµåË∑Ø„ÄÇ‰∏ãÊñπ„ÅÆËµ§„ÅÑ‰∏∏„ÅåÂ∞ëÂπ¥„Åü„Å°„ÅÆË¶ã„Å§„Åã„Å£„ÅüÂ†¥ÊâÄ„ÄÇ‰∫∫„ÅÆÂΩ¢„ÅåÂÆüÈöõ„ÅÆ‰∫∫Èñì„ÅÆË∫´Èï∑„ÄÇÈùí„ÅÑÈÉ®ÂàÜ„ÅØÊΩúÊ∞¥„Åó„Å™„ÅÑ„Å®ÈÄ≤„ÇÅ„Å™„ÅÑ„ÄÇÈ´ò„Åï„Åå1„É°„Éº„Éà„É´„Å´Ê∫Ä„Åü„Å™„ÅÑÁÆáÊâÄ„ÇÇ„ÅÇ„Çã„ÄÇ„Éà„É≥„Éç„É´ÂÜÖ„ÅßÊúÄ„ÇÇÁã≠„ÅÑÈÉ®ÂàÜ„ÅØ„ÄÅ‰∫∫1‰∫∫„Åå„ÇÑ„Å£„Å®ÈÄö„Çå„Çã„Åê„Çâ„ÅÑ„ÅÆ„Çπ„Éö„Éº„Çπ„Åó„Åã„Å™„ÅÑ„ÄÇ‰∏äÊñπ„ÅÆÁôΩ„ÅÑÈÉ®ÂàÜ„ÅØ„ÄÅ„Å®„Åì„Çç„Å©„Åì„ÇçÊµÖ„ÅÑÊ∞¥„Åå„ÅÇ„Çã„Åå„ÄÅ„Åª„Å®„Çì„Å©„Åå‰πæ„ÅÑ„ÅüÂ≤©Â†¥ ÔºàËã±Ë™ûË®ò‰∫ã Cave rescue: Elation as Thai boys and coach freed by diversÔºâ'}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["ds[\"train\"][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"geJpSVE8Da3i","outputId":"5f513708-a5db-4896-bf23-e1ed2eedaf38"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/home/linh/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}],"source":["mt5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_L9H1-fvDa3i"},"outputs":[],"source":["def tokenize_sample_data(data):\n","    input_feature = mt5_tokenizer(data[\"text\"], truncation=True, max_length=1024)\n","    label = mt5_tokenizer(data[\"summary\"], truncation=True, max_length=128)\n","    return {\n","        \"input_ids\": input_feature[\"input_ids\"],\n","        \"attention_mask\": input_feature[\"attention_mask\"],\n","        \"labels\": label[\"input_ids\"],\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ocaCN-W0Da3i","outputId":"24fb7b8f-54b2-43a9-8b1b-97a54f2a535c"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 7113\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 889\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 889\n","    })\n","})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_ds = ds.map(\n","    tokenize_sample_data,\n","    remove_columns=[\"id\", \"url\", \"title\", \"summary\", \"text\"],\n","    batched=True,\n","    batch_size=128)\n","tokenized_ds"]},{"cell_type":"markdown","metadata":{"id":"cwte1ZuPDa3i"},"source":["#**MAIN FUNCTION**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Ckm1Ay2vDa3j","executionInfo":{"status":"ok","timestamp":1718231708861,"user_tz":-420,"elapsed":26,"user":{"displayName":"Ho√†i Linh ƒê√†o","userId":"06427991247119097271"}}},"outputs":[],"source":["class MT5BASE_FT:\n","    def __init__(self, model_name, tokenizer_name, device):\n","        self.device = device\n","        self.model_name = model_name\n","        self.tokenizer_name = tokenizer_name\n","        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n","        self.config = AutoConfig.from_pretrained(\n","            model_name,\n","            max_length=1024,\n","            length_penalty=2.5,\n","            no_repeat_ngram_size=2,\n","            num_beams=15,\n","        )\n","        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name, config=self.config).to(device)\n","        self.data_collator = DataCollatorForSeq2Seq(self.tokenizer, model=self.model, return_tensors=\"pt\")\n","        self.rouge_metric = evaluate.load(\"rouge\")\n","\n","    def tokenize_sentence(self, arg):\n","        encoded_arg = self.tokenizer(arg)\n","        return self.tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n","\n","    def compute_metrics(self, eval_pred):\n","        preds, labels = eval_pred\n","        labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n","\n","        def safe_decode(token_ids):\n","            max_int_value = 2**31 - 1\n","            token_ids = [tid if tid <= max_int_value else self.tokenizer.pad_token_id for tid in token_ids]\n","            return self.tokenizer.decode(token_ids, skip_special_tokens=True)\n","\n","        text_preds = [safe_decode(pred) for pred in preds]\n","        text_labels = [safe_decode(label) for label in labels]\n","\n","        text_preds = [(p if p.endswith((\"!\", \"ÔºÅ\", \"?\", \"Ôºü\", \"„ÄÇ\")) else p + \"„ÄÇ\") for p in text_preds]\n","        text_labels = [(l if l.endswith((\"!\", \"ÔºÅ\", \"?\", \"Ôºü\", \"„ÄÇ\")) else l + \"„ÄÇ\") for l in text_labels]\n","        sent_tokenizer_jp = RegexpTokenizer(u'[^!ÔºÅ?Ôºü„ÄÇ]*[!ÔºÅ?Ôºü„ÄÇ]')\n","        text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(p))) for p in text_preds]\n","        text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(l))) for l in text_labels]\n","\n","        return self.rouge_metric.compute(predictions=text_preds, references=text_labels, tokenizer=self.tokenize_sentence)\n","\n","    def prepare_data_from_lib(self, dataset_name, split='train', subset_indices=None):\n","        dataset = load_dataset(dataset_name, 'japanese', split=split)\n","        def tokenize_function(examples):\n","            model_inputs = self.tokenizer(examples['text'], max_length=self.config.max_length, truncation=True, padding=\"max_length\")\n","            with self.tokenizer.as_target_tokenizer():\n","                labels = self.tokenizer(examples['summary'], max_length=self.config.max_length, truncation=True, padding=\"max_length\")\n","            model_inputs[\"labels\"] = labels[\"input_ids\"]\n","            return model_inputs\n","        tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","        if subset_indices:\n","            tokenized_datasets = Subset(tokenized_datasets, subset_indices)\n","        return DataLoader(tokenized_datasets, batch_size=4, shuffle=split=='train', collate_fn=self.data_collator)\n","\n","    def prepare_data(self, file_path):\n","        df = pd.read_csv(file_path)\n","        train_df, val_df = train_test_split(df, test_size=0.1)\n","        return self._convert_to_loader(train_df), self._convert_to_loader(val_df)\n","\n","    def _convert_to_loader(self, dataframe):\n","        class TextDataset(Dataset):\n","            def __init__(self, tokenizer, data, max_length):\n","                self.tokenizer = tokenizer\n","                self.data = data\n","                self.max_length = max_length\n","\n","            def __len__(self):\n","                return len(self.data)\n","\n","            def __getitem__(self, idx):\n","                item = self.data.iloc[idx]\n","                inputs = self.tokenizer(item['Article'], max_length=self.max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n","                targets = self.tokenizer(item['Summary'], max_length=256, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n","                return {\"input_ids\": inputs.input_ids.squeeze(), \"attention_mask\": inputs.attention_mask.squeeze(), \"labels\": targets.input_ids.squeeze()}\n","\n","        dataset = TextDataset(self.tokenizer, dataframe, 1024)\n","        return DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=self.data_collator)\n","\n","    def train(self, train_dataset, eval_dataset):\n","        training_args = Seq2SeqTrainingArguments(\n","            output_dir=\"./models/checkpoint-improved-mt5-base-step2\",\n","            log_level=\"error\",\n","            num_train_epochs=10,\n","            learning_rate=5e-4,\n","            lr_scheduler_type=\"linear\",\n","            warmup_steps=90,\n","            optim=\"adafactor\",\n","            weight_decay=0.01,\n","            per_device_train_batch_size=4,\n","            per_device_eval_batch_size=2,\n","            gradient_accumulation_steps=16,\n","            evaluation_strategy=\"steps\",\n","            eval_steps=100,\n","            predict_with_generate=True,\n","            generation_max_length=256,\n","            save_steps=500,\n","            logging_steps=10,\n","            push_to_hub=False\n","        )\n","        trainer = Seq2SeqTrainer(\n","            model=self.model,\n","            args=training_args,\n","            data_collator=self.data_collator,\n","            compute_metrics=self.compute_metrics,\n","            train_dataset=train_dataset.dataset,\n","            eval_dataset=eval_dataset.dataset,\n","            tokenizer=self.tokenizer,\n","        )\n","        trainer.train()\n","\n","    def save_model(self, save_directory):\n","        os.makedirs(save_directory, exist_ok=True)\n","        if hasattr(self.model, \"module\"):\n","            self.model.module.save_pretrained(save_directory)\n","        else:\n","            self.model.save_pretrained(save_directory)\n","        print(f\"Model saved in {save_directory}\")\n","\n","    def load_model(self, model_path):\n","        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(self.device)\n","\n","    def predict(self, text):\n","        inputs = self.tokenizer.encode_plus(text, return_tensors=\"pt\", max_length=self.config.max_length, truncation=True, padding=\"max_length\").to(self.device)\n","        summary_ids = self.model.generate(\n","            input_ids=inputs['input_ids'],\n","            attention_mask=inputs['attention_mask'],\n","            num_beams=15,\n","            max_length=256,\n","            length_penalty=2.5, #2.0\n","            early_stopping=True\n","        )\n","        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","        return summary"]},{"cell_type":"markdown","source":["#**RUN FOR STEP1**"],"metadata":{"id":"K53eZguwF7Hu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["6b3837c400d44faaa5ecc773d1162a51","f0ea5326b91e41cb8030ac0fbd24dbe3"]},"id":"KrNgcM-yDa3j","outputId":"99f7a9f5-4166-40fa-886f-121d5c334bf2"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/home/linh/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","/home/linh/.conda/envs/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b3837c400d44faaa5ecc773d1162a51","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/7113 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/linh/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3936: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0ea5326b91e41cb8030ac0fbd24dbe3","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/889 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/linh/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n","/home/linh/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 12.00 MiB. GPU ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m summarizer\u001b[38;5;241m.\u001b[39mprepare_data_from_lib(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsebuetnlp/xlsum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m summarizer\u001b[38;5;241m.\u001b[39mprepare_data_from_lib(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsebuetnlp/xlsum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m, subset_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m \u001b[43msummarizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m summarizer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/mt5-base_model_1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[5], line 78\u001b[0m, in \u001b[0;36mMT5BASE_FT.train\u001b[0;34m(self, train_dataset, eval_dataset)\u001b[0m\n\u001b[1;32m     49\u001b[0m training_args \u001b[38;5;241m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[1;32m     50\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/checkpoint-improved-mt5-base\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     51\u001b[0m     log_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     69\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     70\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m     71\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer,\n\u001b[1;32m     77\u001b[0m )\n\u001b[0;32m---> 78\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/trainer.py:3238\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3241\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/trainer.py:3264\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3263\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3264\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3266\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:186\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m    185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_device\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:203\u001b[0m, in \u001b[0;36mDataParallel.gather\u001b[0;34m(self, outputs, output_device)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgather\u001b[39m(\u001b[38;5;28mself\u001b[39m, outputs: Any, output_device: Union[\u001b[38;5;28mint\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/scatter_gather.py:104\u001b[0m, in \u001b[0;36mgather\u001b[0;34m(outputs, target_device, dim)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Recursive function calls like this create reference cycles.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Setting the function to None clears the refcycle.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mgather_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     gather_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/scatter_gather.py:95\u001b[0m, in \u001b[0;36mgather.<locals>.gather_map\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m outputs):\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll dicts must have the same number of keys\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgather_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_namedtuple(out):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(out)\u001b[38;5;241m.\u001b[39m_make(\u001b[38;5;28mmap\u001b[39m(gather_map, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39moutputs)))\n","File \u001b[0;32m<string>:12\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, loss, logits, past_key_values, decoder_hidden_states, decoder_attentions, cross_attentions, encoder_last_hidden_state, encoder_hidden_states, encoder_attentions)\u001b[0m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/utils/generic.py:389\u001b[0m, in \u001b[0;36mModelOutput.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# if we provided an iterator as first field and the iterator is a (key, value) iterator\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# set the associated fields\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_field_iterator:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iterator):\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(element, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(element) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    393\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(element[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    394\u001b[0m         ):\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    396\u001b[0m                 \u001b[38;5;66;03m# If we do not have an iterator of key/values, set it as attribute\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/scatter_gather.py:95\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m outputs):\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll dicts must have the same number of keys\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(out)((k, \u001b[43mgather_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     96\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m out)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_namedtuple(out):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(out)\u001b[38;5;241m.\u001b[39m_make(\u001b[38;5;28mmap\u001b[39m(gather_map, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39moutputs)))\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/scatter_gather.py:99\u001b[0m, in \u001b[0;36mgather.<locals>.gather_map\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_namedtuple(out):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(out)\u001b[38;5;241m.\u001b[39m_make(\u001b[38;5;28mmap\u001b[39m(gather_map, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39moutputs)))\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgather_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/scatter_gather.py:99\u001b[0m, in \u001b[0;36mgather.<locals>.gather_map\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_namedtuple(out):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(out)\u001b[38;5;241m.\u001b[39m_make(\u001b[38;5;28mmap\u001b[39m(gather_map, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39moutputs)))\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgather_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/scatter_gather.py:89\u001b[0m, in \u001b[0;36mgather.<locals>.gather_map\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     87\u001b[0m out \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/function.py:598\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m     )\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:75\u001b[0m, in \u001b[0;36mGather.forward\u001b[0;34m(ctx, target_device, dim, *inputs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     ctx\u001b[38;5;241m.\u001b[39munsqueezed_scalar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     74\u001b[0m ctx\u001b[38;5;241m.\u001b[39minput_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(i\u001b[38;5;241m.\u001b[39msize(ctx\u001b[38;5;241m.\u001b[39mdim) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/parallel/comm.py:231\u001b[0m, in \u001b[0;36mgather\u001b[0;34m(tensors, dim, destination, out)\u001b[0m\n\u001b[1;32m    227\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing -1 to represent CPU tensor is deprecated. Please use a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice object or string instead, e.g., \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    230\u001b[0m     destination \u001b[38;5;241m=\u001b[39m _get_device_index(destination, allow_cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m destination \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB. GPU "]}],"source":["if __name__ == \"__main__\":\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    summarizer = MT5BASE_FT(\"google/mt5-base\", \"google/mt5-base\", device)\n","    train_dataloader = summarizer.prepare_data_from_lib(\"csebuetnlp/xlsum\", \"train\")\n","    val_dataloader = summarizer.prepare_data_from_lib(\"csebuetnlp/xlsum\", \"validation\", subset_indices=range(20))\n","    summarizer.train(train_dataloader, val_dataloader)\n","    summarizer.save_model(\"./models/mt5-base_model_1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EcwNk_4RDa3j","outputId":"5f34805b-2050-48cd-8cb4-4edb596565dd"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/home/linh/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","/home/linh/.conda/envs/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Original Text: ÊïëÂá∫‰ΩúÊà¶„ÅÆÈñì„ÄÅÊ¥ûÁ™üÂÜÖ„Å´Â∞ëÂπ¥„Åü„Å°„Å®Áïô„Åæ„Å£„Åü„Çø„Ç§Êµ∑Ëªç„ÅÆ„ÉÄ„Ç§„Éê„Éº„Å®ÂåªÂ∏´„ÇÇÊúÄÂæå„Å´ÁÑ°‰∫ãËÑ±Âá∫„Åó„Åü„ÄÇ4‰∫∫„ÅÆÂÜôÁúü„ÅØ10Êó•„ÄÅ„Çø„Ç§Êµ∑ËªçÁâπÊÆäÈÉ®Èöä„Åå„Éï„Çß„Ç§„Çπ„Éñ„ÉÉ„ÇØ„Å´Êé≤Ëºâ„Åó„Åü„ÇÇ„ÅÆ „Çø„Ç§Êµ∑ËªçÁâπÊÆäÈÉ®Èöä„ÅØ„Éï„Çß„Ç§„Çπ„Éñ„ÉÉ„ÇØ„Åß„ÄÅ„Äå„Åì„Çå„ÅØÂ•áË∑°„Å™„ÅÆ„ÅãÁßëÂ≠¶„Å™„ÅÆ„Åã„ÄÅ‰∏Ä‰Ωì‰Ωï„Å™„ÅÆ„Åã„Çà„Åè„Çè„Åã„Çâ„Å™„ÅÑ„ÄÇ„Äé„Ç§„Éé„Ç∑„Ç∑„Äè13‰∫∫„ÅØÂÖ®Âì°„ÄÅÊ¥ûÁ™ü„Åã„ÇâÂá∫„Åü„Äç„Å®ÊïëÂä©‰ΩúÊà¶„ÅÆÁµÇ‰∫Ü„ÇíÂ†±Âëä„Åó„Åü„ÄÇ„Äå„Ç§„Éé„Ç∑„Ç∑„ÄçÔºà„Çø„Ç§Ë™û„Åß„Äå„É†„Éº„Éë„ÄçÔºâ„ÅØÂ∞ëÂπ¥„Åü„Å°„ÅÆÊâÄÂ±û„Åô„Çã„Çµ„ÉÉ„Ç´„Éº„Éª„ÉÅ„Éº„É†„ÅÆÊÑõÁß∞„ÄÇ ÈÅ†Ë∂≥„Å´Âá∫„Åã„Åë„Åü11Ê≠≥„Åã„Çâ17Ê≠≥„ÅÆÂ∞ëÂπ¥„Åü„Å°„Å®25Ê≠≥„ÅÆ„Çµ„ÉÉ„Ç´„Éº„Éª„Ç≥„Éº„ÉÅ„ÅØ6Êúà23Êó•„ÄÅÂ§ßÈõ®„ÅßÂ¢óÊ∞¥„Åó„ÅüÊ¥ûÁ™ü„Åã„ÇâÂá∫„Çâ„Çå„Å™„Åè„Å™„Å£„Åü„ÄÇ„Çø„Ç§ÂÜÖÂ§ñ„Åã„ÇâÈõÜ„Åæ„Å£„Åü„ÉÄ„Ç§„Éê„ÉºÁ¥Ñ90‰∫∫„Å™„Å©„ÅåÊçúÁ¥¢„Å´ÂΩì„Åü„Çä„ÄÅËã±ÂõΩ‰∫∫„ÉÄ„Ç§„Éê„Éº2‰∫∫„Å´„Çà„Å£„Å¶7Êúà2Êó•Â§ú„Å´Áô∫Ë¶ã„Åï„Çå„Åü„ÄÇÂú∞ÂÖÉ„ÅÆ„ÉÅ„Çß„É≥„É©„Ç§ÁúåÁü•‰∫ã„ÇÑ„Çø„Ç§Êµ∑ËªçÁâπÊÆäÈÉ®Èöä„Åå‰∏≠ÂøÉ„Å®„Å™„Å£„ÅüÊïëÂä©Êú¨ÈÉ®„ÅØÂΩìÂàù„ÄÅÊ∞¥„ÅåÂºï„Åè„Åã„ÄÅ„ÅÇ„Çã„ÅÑ„ÅØÂ∞ëÂπ¥„Åü„Å°„ÅåÊΩúÊ∞¥ÊäÄË°ì„ÇíÁøíÂæó„Åô„Çã„Åæ„ÅßÊôÇÈñì„Çí„Åã„Åë„Å¶ËÑ±Âá∫„Åï„Åõ„Çã„Å§„ÇÇ„Çä„Å†„Å£„Åü„Åå„ÄÅÈõ®Â≠£„Å´„Çà„ÇãÊ∞¥‰Ωç‰∏äÊòá„Å®Ê¥ûÁ™üÂÜÖ„ÅÆÈÖ∏Á¥†‰Ωé‰∏ã„ÅÆÈÄ≤Ë°å„ÅåÊá∏Âøµ„Åï„Çå„ÄÅ8Êó•„Åã„Çâ3Êó•ÈÄ£Á∂ö„ÅÆÊïëÂá∫‰ΩúÊà¶„ÅåÊï¢Ë°å„Åï„Çå„Åü„ÄÇ Â∞ëÂπ¥„Åü„Å°„ÅÆËÑ±Âá∫ÊñπÊ≥ï „ÉÄ„Ç§„Éê„Éº„Åü„Å°„Å´ÂâçÂæå„ÇíÊîØ„Åà„Çâ„Çå„ÄÅÊ∞¥Ë∑ØÂÜÖ„Å´Âºµ„ÇäÂ∑°„Çâ„Åï„Çå„Åü„Ç¨„Ç§„Éâ„É≠„Éº„Éó„Çí„Åü„Å©„Çä„Å™„Åå„Çâ„ÄÅÊΩúÊ∞¥ÁµåÈ®ì„ÅÆ„Å™„ÅÑÂ∞ëÂπ¥„Åü„Å°„ÅØËÑ±Âá∫„Åó„Åü„ÄÇ8Êó•„Å´ÊúÄÂàù„ÅÆ4‰∫∫„ÄÅ9Êó•„Å´4‰∫∫„ÄÅ10Êó•„Å´ÊÆã„Çã5‰∫∫„ÅåËÑ±Âá∫„Åó„ÄÅ„Åü„Å†„Å°„Å´Ëøë„Åè„ÅÆ„ÉÅ„Çß„É≥„É©„Ç§Â∏ÇÂÜÖ„ÅÆÁóÖÈô¢„Å´Êê¨ÈÄÅ„Åï„Çå„Åü„ÄÇ2ÈÄ±Èñì‰ª•‰∏äÊ¥ûÁ™ü„Å´Èñâ„ÅòËæº„ÇÅ„Çâ„Çå„Å¶„ÅÑ„Åü„Åì„Å®„ÇíÊÄù„Åà„Å∞„ÄÅÂÖ®Âì°È©ö„Åè„Åª„Å©ÂøÉË∫´„Å®„ÇÇ„Å´ÂÖÉÊ∞ó„Å†„Å®„ÅÑ„ÅÜ„ÄÇ Â∞ëÂπ¥„Åü„Å°„Å®„Ç≥„Éº„ÉÅ„ÅØ„É¨„É≥„Éà„Ç≤„É≥„ÇÑË°ÄÊ∂≤Ê§úÊüª„Å™„Å©„ÇíÂèó„Åë„Åü„ÄÇÂ∞ë„Å™„Åè„Å®„ÇÇ7Êó•Èñì„ÅØ„ÄÅÁµåÈÅéË¶≥ÂØü„ÅÆ„Åü„ÇÅ„Å´ÂÖ•Èô¢„ÇíÁ∂ö„Åë„Çã„Å®„ÅÑ„ÅÜ„ÄÇ Ê¥ûÁ™üÂÜÖ„ÅÆÊ∞¥„ÇíÈ£≤„Åø„ÄÅÈ≥•„ÇÑ„Ç≥„Ç¶„É¢„É™„ÅÆÊéíÊ≥ÑÁâ©„Å´Êé•Ëß¶„Åó„ÅüÂèØËÉΩÊÄß„ÅÆ„ÅÇ„Çã13‰∫∫„ÅØ„ÄÅÁóÖÂéü‰Ωì„Å´ÊÑüÊüì„Åó„Å¶„ÅÑ„Çã„Åä„Åù„Çå„Åå„ÅÇ„Çã„Åü„ÇÅÈöîÈõ¢„Åï„Çå„Å¶„ÅÑ„Çã„ÄÇÂÆ∂Êóè„Å®„ÅØ„Ç¨„É©„ÇπË∂ä„Åó„Å´ÂÜç‰ºö„Åó„Åü„Å®„ÅÑ„ÅÜ„ÄÇ È£ü„ÅπÁâ©„ÅÆ„Åª„Å®„Çì„Å©„Å™„ÅÑÊ¥ûÁ™üÂÜÖ„Åß2ÈÄ±Èñì‰ª•‰∏ä„ÇíÈÅé„Åî„Åó„ÅüÂ∞ëÂπ¥„Åü„Å°„ÅØ‰ΩìÈáç„ÇíÂ§ßÂπÖ„Å´ËêΩ„Å®„Åó„ÄÅÁ©∫ËÖπ„ÇíË®¥„Åà„Å¶„ÅÑ„Åü„ÄÇÊïëÂá∫Âæå„ÅØÂ•ΩÁâ©„ÅÆË±öËÇâ„ÅÆ„ÅîÈ£Ø„ÇÑ„Éë„É≥„ÄÅ„ÉÅ„Éß„Ç≥„É¨„Éº„Éà„Å™„Å©„ÇíÂ∏åÊúõ„Åó„Åü„Åå„ÄÅ„Åó„Å∞„Çâ„Åè„ÅØÊµÅÂãïÈ£ü„ÅåÁ∂ö„Åè„Å®„ÅÑ„ÅÜ„ÄÇ „Åï„Çâ„Å´„ÄÅÂ§ñÁïå„ÅÆÂÖâ„Å´ÁõÆ„ÅåÊÖ£„Çå„Çã„Åæ„Åß„ÅÆÊï∞Êó•„ÅØ„ÄÅ„Çµ„É≥„Ç∞„É©„Çπ„Çí„Åã„Åë„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ Ôºú„Åä„Åô„Åô„ÇÅË®ò‰∫ãÔºû ÊïëÂá∫‰ΩúÊà¶„ÅåÁµÇ„Çè„Çã„Å®„ÄÅÊ¥ûÁ™ü„ÅÆÂá∫Âè£„Å´ÈõÜ„Åæ„Å£„ÅüÊïëÂä©Èñ¢‰øÇËÄÖ„Åã„ÇâÂ§ß„Åç„Å™Ê≠ìÂ£∞„Åå‰∏ä„Åå„Å£„Åü„ÄÇÂ±±„ÅÆ„Åµ„ÇÇ„Å®„Å´„ÅØ„ÄÅÂ∞ëÂπ¥„Åü„Å°„ÅåÊâÄÂ±û„Åô„Çã„Äå„É†„Éº„ÉëÔºà„Ç§„Éé„Ç∑„Ç∑Ôºâ„Äç„Çµ„ÉÉ„Ç´„Éº„ÉÅ„Éº„É†„ÅÆÈñ¢‰øÇËÄÖ„ÅÆÂÆ∂„Åå„ÅÇ„Çä„ÄÅ„Åù„Åì„Å´ÈõÜ„Åæ„Å£„Åü‰∫∫„Åü„Å°„ÇÇÁ¨ëÈ°î„ÅßÂè´„Çì„Å†„ÇäÊ≠ìÂ£∞„ÇíÊåô„Åí„Åü„Çä„Åó„Åü„ÄÇÁèæÂ†¥„Å´„ÅÑ„ÅüBBC„ÅÆ„Ç∏„Éß„Éä„Çµ„É≥„Éª„Éò„ÉÉ„ÉâË®òËÄÖ„ÅØ„ÄÅÂñú„Å∂‰∫∫„Åü„Å°„ÅØ„Äå„Å®„Å¶„ÇÇ„Çø„Ç§‰∫∫„Çâ„Åó„Åè„Å™„ÅÑÊßòÂ≠ê„Åß„Äç„Åï„Åã„Çì„Å´Êè°Êâã„Çí„Åó„Å¶Âõû„Å£„Å¶„ÅÑ„Åü„Å®‰ºù„Åà„Åü„ÄÇ Â∞ëÂπ¥„Åü„Å°„Å∏„ÅÆÁ≤æÁ•ûÁöÑÂΩ±Èüø„ÅØÔºü „Çø„Ç§Ê¥ûÁ™üÊïëÂä© „ÉÅ„Çß„É≥„É©„Ç§Â∏Ç„Åß„ÅØ„ÄÅÂÖ®Âì°ËÑ±Âá∫„ÅÆÁü•„Çâ„Åõ„Å´ÂæÄÊù•„ÅÆËªä„ÅØÊ¨°„ÄÖ„Å´„ÇØ„É©„ÇØ„Ç∑„Éß„É≥„ÇíÈ≥¥„Çâ„Åó„Å¶Âñú„Çì„Å†„ÄÇÂ≠ê‰æõ„Åü„Å°„ÇÑ„Ç≥„Éº„ÉÅ„ÅåÊê¨ÈÄÅ„Åï„Çå„ÅüÁóÖÈô¢„ÅÆÂ§ñ„Å´ÈõÜ„Åæ„Å£„Å¶„ÅÑ„Åü‰∫∫„Åü„Å°„ÅØ„ÄÅ‰∏ÄÊñâ„Å´ÊãçÊâã„Åó„Åü„ÄÇ „ÇΩ„Éº„Ç∑„É£„É´„É°„Éá„Ç£„Ç¢„Åß„ÅØ„Çø„Ç§‰∫∫„ÅÆÂ§ö„Åè„Åå„ÄÅ„Äå#Heroes(Ëã±ÈõÑÔºâ„Äç„ÄÅ„Äå #ThankyouÔºà„ÅÇ„Çä„Åå„Å®„ÅÜÔºâ„Äç„Å™„Å©„ÅÆ„Éè„ÉÉ„Ç∑„É•„Çø„Ç∞„Çí‰Ωø„Å£„Å¶„ÄÅ„Åù„Çå„Åû„Çå„Å´ÊÄù„ÅÑ„ÇíË°®Áèæ„Åó„Å¶„ÅÑ„Åü„ÄÇ 13‰∫∫„ÅØ2Êó•„ÄÅÊ¥ûÁ™üÂÜÖ„ÅÆÂ≤©Â†¥„Å´Ë∫´„ÇíÂØÑ„Åõ„Å¶„ÅÑ„Çã„Å®„Åì„Çç„ÇíÁô∫Ë¶ã„Åï„Çå„Åü„ÄÇ‰∏≠Â§Æ„ÅÆÂ∞ëÂπ¥„ÅØ„ÄÅ„Çµ„ÉÉ„Ç´„Éº„ÅÆ„Ç§„É≥„Ç∞„É©„É≥„Éâ‰ª£Ë°®„ÅÆ„Ç∑„É£„ÉÑ„ÇíÁùÄ„Å¶„ÅÑ„Çã„ÄÇÂÜôÁúü„ÅØ„Çø„Ç§Êµ∑Ëªç„Åå4Êó•„Å´ÂÖ¨Ë°®„Åó„Åü„Éì„Éá„Ç™„Çà„Çä „Çµ„ÉÉ„Ç´„ÉºÁïå„ÇÇÂ∞ëÂπ¥„Åü„Å°„Å®„Ç≥„Éº„ÉÅ„ÅÆÁÑ°‰∫ã„ÇíÂ§ß„ÅÑ„Å´Âñú„Å≥„ÄÅËã±„Éû„É≥„ÉÅ„Çß„Çπ„Çø„Éº„Éª„É¶„Éä„Ç§„ÉÜ„ÉÉ„Éâ„ÇÑ„Éù„É´„Éà„Ç¨„É´„ÅÆ„Éô„É≥„Éï„Ç£„Ç´„ÅåÂÖ®Âì°„ÇíË©¶Âêà„Å´ÊãõÂæÖ„Åó„Åü„ÄÇÂõΩÈöõ„Çµ„ÉÉ„Ç´„ÉºÈÄ£ÁõüÔºàFIFAÔºâ„ÇÇ„ÄÅÂ∞ëÂπ¥„Åü„Å°„Çí„É≠„Ç∑„Ç¢„ÅßÈñãÂÇ¨„Åï„Çå„Å¶„ÅÑ„Çã„ÉØ„Éº„É´„Éâ„Ç´„ÉÉ„Éó„ÅÆ15Êó•„Å´„ÅÇ„ÇãÊ±∫ÂãùÊà¶„Å´Êãõ„ÅÑ„Åü„Åå„ÄÅ„Åì„Çå„ÅØÂõûÂæ©„ÅåÈñì„Å´Âêà„Çè„Å™„ÅÑ„Å®„ÅÑ„ÅÜÁêÜÁî±„ÅßË¶ãÈÄÅ„Çâ„Çå„Åü„ÄÇ „ÉØ„Éº„É´„Éâ„Ç´„ÉÉ„Éó„ÅÆÊ∫ñÊ±∫Âãù„Å´ÂÇô„Åà„Çã„Ç§„É≥„Ç∞„É©„É≥„Éâ‰ª£Ë°®„ÅÆDF„Ç´„Ç§„É´„Éª„Ç¶„Ç©„Éº„Ç´„Éº„ÅØ„ÄÅ„Ç§„É≥„Ç∞„É©„É≥„Éâ„ÅÆ„É¶„Éã„Éï„Ç©„Éº„É†„ÇíÂ∞ëÂπ¥„Åü„Å°„Å´Ë¥à„Çä„Åü„ÅÑ„Å®„ÉÑ„Ç§„Éº„Éà„Åó„Åü„ÄÇÂ∞ëÂπ¥„ÅÆ1‰∫∫„ÅØÊ¥ûÁ™üÂÜÖ„Åß„ÄÅ„Ç§„É≥„Ç∞„É©„É≥„Éâ„ÅÆ„Ç∏„É£„Éº„Ç∏„Éº„ÇíÁùÄ„Å¶„ÅÑ„Åü„ÄÇ„Åô„Çã„Å®Ëã±Â§ñÂãôÁúÅ„ÅÆÂÖ¨Âºè„Ç¢„Ç´„Ç¶„É≥„Éà„Åå„Åì„Çå„Å´Âøú„Åà„Å¶„ÄÅ„Äå„ÇÑ„ÅÇ„ÄÅ„Ç´„Ç§„É´„ÄÇÈßê„Çø„Ç§Ëã±ÂõΩÂ§ß‰Ωø„Å®Ë©±„Çí„Åó„Åü„ÄÇ„Ç§„É≥„Ç∞„É©„É≥„Éâ„ÅÆ„Ç∑„É£„ÉÑ„ÇíÂãáÊï¢„Å™Â∞ëÂπ¥„Åü„Å°„Å´„ÄÅÂñú„Çì„Åß„ÄÅÁ¢∫ÂÆü„Å´Â±ä„Åë„Å¶„Åè„Çå„Çã„Åù„ÅÜ„Å†„Äç„Å®„ÉÑ„Ç§„Éº„Éà„Åó„Åü„ÄÇ ÁµåÈ®ìË±äÂØå„Å™„ÉÄ„Ç§„Éê„Éº„Å´„Å®„Å£„Å¶„ÇÇ„ÄÅÂ∞ëÂπ¥„Åü„Å°„ÅÆ„ÅÑ„ÇãÂ†¥ÊâÄ„Åæ„Åß„ÅÆÂæÄÂæ©„ÅØÈáçÂä¥ÂÉç„Å†„Å£„Åü„ÄÇÂÖÉ„Çø„Ç§Êµ∑ËªçÊΩúÊ∞¥Â£´„ÅÆ„Çµ„Éû„É≥„Éª„Ç∞„Éä„É≥„Åï„Çì„ÅØ6Êó•„ÄÅÂ∞ëÂπ¥„Åü„Å°„Å´Á©∫Ê∞ó„Éú„É≥„Éô„ÇíÈÅã„Å∂‰ªªÂãô„ÇíÊûú„Åü„Åó„Å¶Êàª„Çç„ÅÜ„Å®„Åó„Å¶„ÅÑ„Åü„Å®„Åì„Çç„ÄÅÈÖ∏Á¥†‰∏çË∂≥„ÅßÂëΩ„ÇíËêΩ„Å®„Åó„Åü„ÄÇ „ÉÄ„Ç§„Éê„Éº„Åü„Å°„ÅåÂá∫Âè£„Åæ„ÅßÂºµ„Å£„Åü„Ç¨„Ç§„Éâ„É≠„Éº„Éó„Çí„Åü„Å©„Çä„Å™„Åå„Çâ„ÄÅÂ∞ëÂπ¥„Åü„Å°„ÅØÂ†¥ÊâÄ„Å´„Çà„Å£„Å¶„ÄÅÊ≠©„ÅÑ„Åü„Çä„ÄÅÊ∞¥„ÅÆ‰∏≠„ÇíÊ≠©„ÅÑ„Åü„Çä„ÄÅÁôª„Å£„Åü„ÇäÊΩú„Å£„Åü„Çä„Åó„Å¶Â§ñ„Å´Âá∫„Åü„ÄÇ Â∞ëÂπ¥„Åü„Å°„ÅØ„ÄÅÈÄöÂ∏∏„ÅÆ„Éû„Çπ„ÇØ„Çà„Çä„ÇÇÂàùÂøÉËÄÖ„Å´ÈÅ©„Åó„ÅüÈ°îÈÉ®ÂÖ®‰Ωì„ÇíË¶Ü„ÅÜ„Éû„Çπ„ÇØ„Çí„Åã„Å∂„Å£„Åü„ÄÇÂ∞ëÂπ¥1‰∫∫„Å´„Å§„Åç2‰∫∫„ÅÆ„ÉÄ„Ç§„Éê„Éº„Åå‰ªò„Åç„ÄÅ„ÉÄ„Ç§„Éê„Éº„ÅåÂ∞ëÂπ¥„ÅÆÁ©∫Ê∞ó„Éú„É≥„Éô„ÇíÈÅã„Çì„Å†„ÄÇ ÊúÄ„ÇÇÂõ∞Èõ£„Å™„ÅÆ„ÅØ„ÄÅÊ¥ûÁ™ü„ÅÆ‰∏≠„Åª„Å©„Å´„ÅÇ„Çã„ÄåT„Ç∏„É£„É≥„ÇØ„Ç∑„Éß„É≥„Äç„Å®Âëº„Å∞„Çå„Å¶„ÅÑ„ÇãÂ†¥ÊâÄ„Åß„ÄÅ„ÅÇ„Åæ„Çä„Å´Áã≠„ÅÑ„Åü„ÇÅ„ÄÅ„ÉÄ„Ç§„Éê„Éº„ÅØÁ©∫Ê∞ó„Éú„É≥„Éô„ÇíÂ§ñ„Åó„Å¶ÈÄ≤„ÇÄÂøÖË¶Å„Åå„ÅÇ„Å£„Åü„ÄÇ T„Ç∏„É£„É≥„ÇØ„Ç∑„Éß„É≥„ÇíÊäú„Åë„Çã„Å®„ÄÅ„ÉÄ„Ç§„Éê„ÉºÈÅî„ÅÆÂü∫Âú∞„Å®„Å™„Å£„Å¶„ÅÑ„Çã„ÄåÁ¨¨3ÂÆ§„Äç„Åå„ÅÇ„Çä„ÄÅÂ∞ëÂπ¥„Åü„Å°„ÅØ„Åì„Åì„ÅßÂá∫Âè£„Å∏Âêë„Åã„ÅÜÂâç„Å´‰ºëÊÅØ„Åå„Å®„Çå„Åü„ÄÇ Â∞ëÂπ¥„Çâ„ÅÆÊïëÂá∫ÁµåË∑Ø„ÄÇ‰∏ãÊñπ„ÅÆËµ§„ÅÑ‰∏∏„ÅåÂ∞ëÂπ¥„Åü„Å°„ÅÆË¶ã„Å§„Åã„Å£„ÅüÂ†¥ÊâÄ„ÄÇ‰∫∫„ÅÆÂΩ¢„ÅåÂÆüÈöõ„ÅÆ‰∫∫Èñì„ÅÆË∫´Èï∑„ÄÇÈùí„ÅÑÈÉ®ÂàÜ„ÅØÊΩúÊ∞¥„Åó„Å™„ÅÑ„Å®ÈÄ≤„ÇÅ„Å™„ÅÑ„ÄÇÈ´ò„Åï„Åå1„É°„Éº„Éà„É´„Å´Ê∫Ä„Åü„Å™„ÅÑÁÆáÊâÄ„ÇÇ„ÅÇ„Çã„ÄÇ„Éà„É≥„Éç„É´ÂÜÖ„ÅßÊúÄ„ÇÇÁã≠„ÅÑÈÉ®ÂàÜ„ÅØ„ÄÅ‰∫∫1‰∫∫„Åå„ÇÑ„Å£„Å®ÈÄö„Çå„Çã„Åê„Çâ„ÅÑ„ÅÆ„Çπ„Éö„Éº„Çπ„Åó„Åã„Å™„ÅÑ„ÄÇ‰∏äÊñπ„ÅÆÁôΩ„ÅÑÈÉ®ÂàÜ„ÅØ„ÄÅ„Å®„Åì„Çç„Å©„Åì„ÇçÊµÖ„ÅÑÊ∞¥„Åå„ÅÇ„Çã„Åå„ÄÅ„Åª„Å®„Çì„Å©„Åå‰πæ„ÅÑ„ÅüÂ≤©Â†¥ ÔºàËã±Ë™ûË®ò‰∫ã Cave rescue: Elation as Thai boys and coach freed by diversÔºâ\n","Summary: „Çø„Ç§ÂåóÈÉ®„ÅÆÊ¥ûÁ™ü„Åß2Êó•„ÄÅ„Çµ„ÉÉ„Ç´„Éº„ÅÆ„Ç§„É≥„Ç∞„É©„É≥„Éâ‰ª£Ë°®„ÅÆ„Ç∏„É£„Éº„Ç∏„Éº„ÇíÁùÄ„Å¶„ÅÑ„ÅüÂ∞ëÂπ¥13‰∫∫„ÅåËÑ±Âá∫„Åó„Åü„ÄÇÂú∞ÂÖÉÂΩìÂ±Ä„ÅåÁô∫Ë°®„Åó„Åü„ÄÇ\n","GT: „Çø„Ç§ÂåóÈÉ®„ÅÆ„Çø„É†„É´„Ç¢„É≥Ê¥ûÁ™ü„Åß10Êó•Â§ú„ÄÅ‰∏≠„Å´Èñâ„ÅòËæº„ÇÅ„Çâ„Çå„Å¶„ÅÑ„ÅüÂ∞ëÂπ¥12‰∫∫„Å®„Çµ„ÉÉ„Ç´„Éº„Éª„Ç≥„Éº„ÉÅ„ÅÆË®à13‰∫∫„ÅÆ„ÅÜ„Å°„ÄÅÊúÄÂæå„ÅÆÂ∞ëÂπ¥4‰∫∫„Å®„Ç≥„Éº„ÉÅ„ÅåÊ∞¥Ë∑Ø„ÇíÊΩú„ÇäÁÑ°‰∫ãËÑ±Âá∫„Åó„Åü„ÄÇ„Åù„ÅÆÁ¥Ñ3ÊôÇÈñìÂæå„Å´„ÅØ„ÄÅÊ¥ûÁ™üÂÜÖ„ÅßÂ∞ëÂπ¥„Åü„Å°„Å®Áïô„Åæ„Å£„Å¶„ÅÑ„ÅüÊµ∑Ëªç„ÉÄ„Ç§„Éê„Éº3‰∫∫„Å®ÂåªÂ∏´„ÇÇÁîüÈÇÑ„Åó„Åü„ÄÇ17Êó•Èñì„ÇÇÊ¥ûÁ™üÂÜÖ„Å´„ÅÑ„Åü13‰∫∫„ÅÆÊïëÂá∫„Å´„ÄÅ„Çø„Ç§ÂõΩÂÜÖÂ§ñ„ÅßÂ§ö„Åè„ÅÆ‰∫∫„ÅåÂÆâÂøÉ„Åó„ÄÅÂñú„Çì„Åß„ÅÑ„Çã„ÄÇ\n","Original Text Lenght: 2242\n","Summary Lenght: 56\n","GT Lenght: 158\n"]}],"source":["if __name__ == \"__main__\":\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    summarizer = MT5BASE_FT(\"google/mt5-base\", \"google/mt5-base\", device)\n","    # model_path = \"./models/mt5-base_model_1\"\n","    ds = load_dataset(\"csebuetnlp/xlsum\", \"japanese\")\n","    input_for_test = ds[\"train\"][0]['text']\n","    gt_for_test = ds[\"train\"][0]['summary']\n","    model_path = \"./models/mt5-base_model_1\"\n","    summarizer.load_model(model_path)\n","\n","    summary = summarizer.predict(input_for_test)\n","    print(f\"Original Text: {input_for_test}\")\n","    print(f\"Summary: {summary}\")\n","    print(f\"GT: {gt_for_test}\")\n","    print(f\"Original Text Lenght: {len(input_for_test)}\")\n","    print(f\"Summary Lenght: {len(summary)}\")\n","    print(f\"GT Lenght: {len(gt_for_test)}\")"]},{"cell_type":"markdown","source":["#**RUN FOR STEP2**"],"metadata":{"id":"75ffIaTiGCyX"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    summarizer = MT5BASE_FT(\"/content/drive/MyDrive/AI/VJ/mt5-work/models/mt5-base_model_1\", \"google/mt5-base\", device)\n","    train_loader, val_loader = summarizer.prepare_data(\"/content/drive/MyDrive/AI/VJ/mt5-work/data/articles_and_summaries.csv\")\n","    summarizer.train(train_loader, val_loader)\n","    summarizer.save(\"/content/drive/MyDrive/AI/VJ/mt5-work/models/mt5-base_model_2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["df09e77c490540dcba4e35738c8892a4","6ff273749d5e4dfcb99ae70778ed18b9","f3bc23078fcf475182d3974889bfba74","82243ee74b144bff86bc6824300b13db","70387243aad14167a3d494a6fbb1470f","225436dfdec248c283437a29132f7016","60e463cc7a924ea693b9c3b374956c4c","debe4408e1494a2bb6623088d62b3afd","1c4539ccc9674cc1855044c240cfc530","3718bbba57304aa58e67e10fe7a2f521","5fec5b50871040149c04acea4b507e02","a1c47e7dbecf4e0bb03f4203f6050ce4","bbdfbf4316f94021a9e3b5aadf51371e","864e2d8e3b52424a8fa5d0a14b7a2b88","643552f7668447e8acbd26bebc7f048a","b563cf828bd04604bf1281e04147d3aa","f77f1503c2e548bb8a003ba0483e0dfd","b06cce3764c34375897b05d2922201f8","2bc2c17137714172803a3dc6314b530e","8c20c47f13714d848f317c485f1a3c8d","f0dc99c4762547019ead7f7967357d2f","36c93eedef414e6f9c204da7d73fe2b4","99069423ad5644448e681db25b4c8ef0","cdddd5490f6041d1807715b8b6bbc517","fd66a8f5141f4983815142a6ed890149","f5b0e5e2308144f5b40392e669edef6f","6e569574465440b5a42183b0db6de8be","c144b4deb5784f68889ea54523fa29b0","029ce68c13674fc39fc723968f32998e","89fa7b5b92794da1984abb9f67c1ff62","b258803f9fe64169867497bdf1bc9bc6","ddda41b0f56c48a9b4b767f49b6ada30","dd371a3bccdf479c8a528706ca12b893","e81e236d4afb4e7f8e9e7ad131cbc314","07410f62cef54eabad4a0be39f559909","27f0633543ef47058b2892d7cf82b486","3f5cc8a24c5a429ea200dfde1e9e56fd","776e53199dbb493c919d3ce16c4784d8","675dc9efce4f429090d8fddcb7f7a854","96ab1b72270c413e8214016a1e1f7ebc","43fc60412954449c945cc4e7ba83f904","5f77ccbe29314d638c76dcccdaf1059b","dfc8f63cc1274aad8a7ad8eec52e4dd8","349957e9361d4b82a36025836652633e","aa51de248f8145a2946288b0ef805b0f","12f8500374384a6ca01420be15d80565","7c59a3557af24bfb9a6e231c0974c6e8","71719307b9a949988e90429dc8dec7d0","a09c776edc90400eb310d8630d40a41f","9ec0757208fa42fbae86f73c79fdcc0b","378a80c71a174604a0ed10a80db9fd23","9cde20c5efce475f99766c8a34895a92","5ee81008f9d0461085599310ad96e0d5","d162d6c2ea0d4ed1aa68511e9b2bebc5","dec0ccc23c51402899713c1a4d4b84d1"]},"id":"RDXRaZTFGB6n","outputId":"7a6c505d-3f1c-4021-a48d-f55ee62ca640","executionInfo":{"status":"error","timestamp":1718247758424,"user_tz":-420,"elapsed":4475060,"user":{"displayName":"Ho√†i Linh ƒê√†o","userId":"06427991247119097271"}}},"execution_count":7,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df09e77c490540dcba4e35738c8892a4","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1c47e7dbecf4e0bb03f4203f6050ce4","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99069423ad5644448e681db25b4c8ef0","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e81e236d4afb4e7f8e9e7ad131cbc314","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa51de248f8145a2946288b0ef805b0f","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:646: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n","  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='447' max='740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [447/740 3:11:48 < 2:06:17, 0.04 it/s, Epoch 5.96/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.373900</td>\n","      <td>0.351628</td>\n","      <td>0.517548</td>\n","      <td>0.305860</td>\n","      <td>0.452948</td>\n","      <td>0.473774</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.308400</td>\n","      <td>0.312463</td>\n","      <td>0.522325</td>\n","      <td>0.318107</td>\n","      <td>0.467535</td>\n","      <td>0.487255</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.272200</td>\n","      <td>0.300020</td>\n","      <td>0.561598</td>\n","      <td>0.341907</td>\n","      <td>0.494222</td>\n","      <td>0.522320</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.228500</td>\n","      <td>0.297878</td>\n","      <td>0.550322</td>\n","      <td>0.337415</td>\n","      <td>0.486750</td>\n","      <td>0.510103</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='601' max='740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [601/740 4:11:27 < 58:21, 0.04 it/s, Epoch 8.02/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.373900</td>\n","      <td>0.351628</td>\n","      <td>0.517548</td>\n","      <td>0.305860</td>\n","      <td>0.452948</td>\n","      <td>0.473774</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.308400</td>\n","      <td>0.312463</td>\n","      <td>0.522325</td>\n","      <td>0.318107</td>\n","      <td>0.467535</td>\n","      <td>0.487255</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.272200</td>\n","      <td>0.300020</td>\n","      <td>0.561598</td>\n","      <td>0.341907</td>\n","      <td>0.494222</td>\n","      <td>0.522320</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.228500</td>\n","      <td>0.297878</td>\n","      <td>0.550322</td>\n","      <td>0.337415</td>\n","      <td>0.486750</td>\n","      <td>0.510103</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.204200</td>\n","      <td>0.295702</td>\n","      <td>0.556656</td>\n","      <td>0.345299</td>\n","      <td>0.494321</td>\n","      <td>0.517452</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='266' max='266' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [266/266 14:59]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"error","ename":"OverflowError","evalue":"out of range integral type conversion attempted","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-816402a5c3c6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msummarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMT5BASE_FT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/AI/VJ/mt5-work/models/mt5-base_model_1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"google/mt5-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/AI/VJ/mt5-work/data/articles_and_summaries.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msummarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msummarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/AI/VJ/mt5-work/models/mt5-base_model_2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-95b5d2c5ce4f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, eval_dataset)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         )\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2289\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2291\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2292\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2719\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     def predict(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3572\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3573\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3574\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3852\u001b[0m                 )\n\u001b[1;32m   3853\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3854\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3855\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3856\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-95b5d2c5ce4f>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(self, eval_pred)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtext_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtext_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtext_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ÔºÅ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ôºü\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"„ÄÇ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"„ÄÇ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_preds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3794\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdecoded\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3795\u001b[0m         \"\"\"\n\u001b[0;32m-> 3796\u001b[0;31m         return [\n\u001b[0m\u001b[1;32m   3797\u001b[0m             self.decode(\n\u001b[1;32m   3798\u001b[0m                 \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3795\u001b[0m         \"\"\"\n\u001b[1;32m   3796\u001b[0m         return [\n\u001b[0;32m-> 3797\u001b[0;31m             self.decode(\n\u001b[0m\u001b[1;32m   3798\u001b[0m                 \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3799\u001b[0m                 \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3834\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_py_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3836\u001b[0;31m         return self._decode(\n\u001b[0m\u001b[1;32m   3837\u001b[0m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3838\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         clean_up_tokenization_spaces = (\n","\u001b[0;31mOverflowError\u001b[0m: out of range integral type conversion attempted"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1cf1455a73444e5eb3d1c3121a10d51b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6614e6c3170409aaba5b95454719a34","IPY_MODEL_4257aa2e4c1b45bb95847016e8e800ff","IPY_MODEL_01d44f733dc64e33bb44ea0d8c7ac3fe"],"layout":"IPY_MODEL_1811f10e28604e90bf695672b8caeba6"}},"d6614e6c3170409aaba5b95454719a34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bce50c532e047dca91dd2adc632d920","placeholder":"‚Äã","style":"IPY_MODEL_b6c6abbc5b9c4aecac0e7b0a2ffe6f7d","value":"Downloading‚Äádata:‚Äá100%"}},"4257aa2e4c1b45bb95847016e8e800ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fabedc1808c4e28b992234fb99963ef","max":21063776,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6491d7f89e724f0e9545412a3dbf4e02","value":21063776}},"01d44f733dc64e33bb44ea0d8c7ac3fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c45d0d21fd7d42cf86ab02c90340204a","placeholder":"‚Äã","style":"IPY_MODEL_cde91f5a4f4a4a8488d61ec949de92db","value":"‚Äá21.1M/21.1M‚Äá[00:04&lt;00:00,‚Äá5.85MB/s]"}},"1811f10e28604e90bf695672b8caeba6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bce50c532e047dca91dd2adc632d920":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6c6abbc5b9c4aecac0e7b0a2ffe6f7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fabedc1808c4e28b992234fb99963ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6491d7f89e724f0e9545412a3dbf4e02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c45d0d21fd7d42cf86ab02c90340204a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cde91f5a4f4a4a8488d61ec949de92db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ee99f7892cb4fa2a4db015f40023790":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0056d0a29cf4982b850babf1e7b0220","IPY_MODEL_7b9b630d9bea453f854ca476d02276e6","IPY_MODEL_8a07932f6c7745b295bd8f646811a83b"],"layout":"IPY_MODEL_c81a75b44acb4974a1304a4a99f64de7"}},"f0056d0a29cf4982b850babf1e7b0220":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bff5aa092144d29b35878ff82f5fa44","placeholder":"‚Äã","style":"IPY_MODEL_f0396c376eb74545b90740696a44cc53","value":"Downloading‚Äádata:‚Äá100%"}},"7b9b630d9bea453f854ca476d02276e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_693c5b04a17f4760911a5a247444f2ca","max":2544059,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05f6646e646647adb856865493ca5bef","value":2544059}},"8a07932f6c7745b295bd8f646811a83b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cd0372a52904d47ac3edc816771a328","placeholder":"‚Äã","style":"IPY_MODEL_4df77d52155146888201922a500185e0","value":"‚Äá2.54M/2.54M‚Äá[00:02&lt;00:00,‚Äá948kB/s]"}},"c81a75b44acb4974a1304a4a99f64de7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bff5aa092144d29b35878ff82f5fa44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0396c376eb74545b90740696a44cc53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"693c5b04a17f4760911a5a247444f2ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05f6646e646647adb856865493ca5bef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0cd0372a52904d47ac3edc816771a328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4df77d52155146888201922a500185e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21f241cfea3c43cab8039f9d1a00b09f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9f292a70a3b420e8b06a287983c2a12","IPY_MODEL_d475611e5ae54004b39471566d15fe9a","IPY_MODEL_c4ab2bc6a59b4241802cf0c73d0bf206"],"layout":"IPY_MODEL_e8dcf9b4e88b4c1c854e594d673087b0"}},"f9f292a70a3b420e8b06a287983c2a12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a970946bd3414fa6816c7aadcd488e14","placeholder":"‚Äã","style":"IPY_MODEL_fcbba861ba1949ae8648849907cf3609","value":"Downloading‚Äádata:‚Äá100%"}},"d475611e5ae54004b39471566d15fe9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7220410a6f234fe78a5ec0b91c0f49f8","max":2482724,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50a8156bd3d544b48f3ed0a6b891cb17","value":2482724}},"c4ab2bc6a59b4241802cf0c73d0bf206":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3354094bcd24d46809ef99c573d9c79","placeholder":"‚Äã","style":"IPY_MODEL_64cef3f116bf4c05b15c6660c9fc63e5","value":"‚Äá2.48M/2.48M‚Äá[00:02&lt;00:00,‚Äá837kB/s]"}},"e8dcf9b4e88b4c1c854e594d673087b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a970946bd3414fa6816c7aadcd488e14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcbba861ba1949ae8648849907cf3609":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7220410a6f234fe78a5ec0b91c0f49f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50a8156bd3d544b48f3ed0a6b891cb17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3354094bcd24d46809ef99c573d9c79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64cef3f116bf4c05b15c6660c9fc63e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce4a6a1415144a84be431675e1d317d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4065af0cca74684bb6983da03d3db64","IPY_MODEL_f65fe8852a2b401b8bebce7e48f9d364","IPY_MODEL_c3b7ef83f11f41d288918238924e13c0"],"layout":"IPY_MODEL_6028e1d34bab4f5eade76ad986174a0a"}},"c4065af0cca74684bb6983da03d3db64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_399701a5b9db478bab74f93c07405b22","placeholder":"‚Äã","style":"IPY_MODEL_c4368051b8734fdb89d50afe72c7efdd","value":"Generating‚Äátrain‚Äásplit:‚Äá100%"}},"f65fe8852a2b401b8bebce7e48f9d364":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f469bbb714245e7bdf3ffaadc06f61f","max":7113,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63f31f5f0c384ce5b3448300d5412d3e","value":7113}},"c3b7ef83f11f41d288918238924e13c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60401a40a61646b19b06fd6e2d963e70","placeholder":"‚Äã","style":"IPY_MODEL_922c02e0413b44218acac27a9fe4e7ad","value":"‚Äá7113/7113‚Äá[00:00&lt;00:00,‚Äá32552.39‚Äáexamples/s]"}},"6028e1d34bab4f5eade76ad986174a0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"399701a5b9db478bab74f93c07405b22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4368051b8734fdb89d50afe72c7efdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f469bbb714245e7bdf3ffaadc06f61f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63f31f5f0c384ce5b3448300d5412d3e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60401a40a61646b19b06fd6e2d963e70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"922c02e0413b44218acac27a9fe4e7ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c43ef7987f64a5a97581b8b718f8dd1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80d71f5ec03449eaa2e49f569cc93a8d","IPY_MODEL_239cb5706351413fa4a15ed42d022348","IPY_MODEL_2754936e9ed74dac8d7d53e5a61f9d7b"],"layout":"IPY_MODEL_249cf1379f864d34b0ee9f79b3966a47"}},"80d71f5ec03449eaa2e49f569cc93a8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48a32d0550244fc0a0398fe4e208bafe","placeholder":"‚Äã","style":"IPY_MODEL_27ac1b2b91314eaa84a6c0e9a361749c","value":"Generating‚Äátest‚Äásplit:‚Äá100%"}},"239cb5706351413fa4a15ed42d022348":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_550c8051bbf044fba2c10dc5e0ce1dae","max":889,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b752d8402d7435e91bcc806e969eb43","value":889}},"2754936e9ed74dac8d7d53e5a61f9d7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bae4635c7754fe1bdaf11e46141d570","placeholder":"‚Äã","style":"IPY_MODEL_b87a05de18534c9da06d812ef230a938","value":"‚Äá889/889‚Äá[00:00&lt;00:00,‚Äá19238.54‚Äáexamples/s]"}},"249cf1379f864d34b0ee9f79b3966a47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48a32d0550244fc0a0398fe4e208bafe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27ac1b2b91314eaa84a6c0e9a361749c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"550c8051bbf044fba2c10dc5e0ce1dae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b752d8402d7435e91bcc806e969eb43":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bae4635c7754fe1bdaf11e46141d570":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b87a05de18534c9da06d812ef230a938":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edf7ae9bdc1a4fdcbddd88ef6b6b996b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_175f8038a1294f52828c9327e0ba0ec8","IPY_MODEL_05391904ef58406b9a6afc230c649e6e","IPY_MODEL_6e3eb2770ea34144a7170fd24084ff8c"],"layout":"IPY_MODEL_91c95f3254744db99d39ab5c78415af1"}},"175f8038a1294f52828c9327e0ba0ec8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_998c9f5c4449462eb0b6a74f68c859c6","placeholder":"‚Äã","style":"IPY_MODEL_2daa6fff41ea4beabaec587d0528609c","value":"Generating‚Äávalidation‚Äásplit:‚Äá100%"}},"05391904ef58406b9a6afc230c649e6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f7e14863ad046eaa70bbdd9e5243c5c","max":889,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e92fbb466a9740bd9bdaa354acd858b3","value":889}},"6e3eb2770ea34144a7170fd24084ff8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e7dab09b9b144beaf1c1063897641b6","placeholder":"‚Äã","style":"IPY_MODEL_c8623e401cf645e091ef196820def42c","value":"‚Äá889/889‚Äá[00:00&lt;00:00,‚Äá21632.16‚Äáexamples/s]"}},"91c95f3254744db99d39ab5c78415af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"998c9f5c4449462eb0b6a74f68c859c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2daa6fff41ea4beabaec587d0528609c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f7e14863ad046eaa70bbdd9e5243c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e92fbb466a9740bd9bdaa354acd858b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e7dab09b9b144beaf1c1063897641b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8623e401cf645e091ef196820def42c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df09e77c490540dcba4e35738c8892a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ff273749d5e4dfcb99ae70778ed18b9","IPY_MODEL_f3bc23078fcf475182d3974889bfba74","IPY_MODEL_82243ee74b144bff86bc6824300b13db"],"layout":"IPY_MODEL_70387243aad14167a3d494a6fbb1470f"}},"6ff273749d5e4dfcb99ae70778ed18b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_225436dfdec248c283437a29132f7016","placeholder":"‚Äã","style":"IPY_MODEL_60e463cc7a924ea693b9c3b374956c4c","value":"tokenizer_config.json:‚Äá100%"}},"f3bc23078fcf475182d3974889bfba74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_debe4408e1494a2bb6623088d62b3afd","max":376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c4539ccc9674cc1855044c240cfc530","value":376}},"82243ee74b144bff86bc6824300b13db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3718bbba57304aa58e67e10fe7a2f521","placeholder":"‚Äã","style":"IPY_MODEL_5fec5b50871040149c04acea4b507e02","value":"‚Äá376/376‚Äá[00:00&lt;00:00,‚Äá36.0kB/s]"}},"70387243aad14167a3d494a6fbb1470f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"225436dfdec248c283437a29132f7016":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60e463cc7a924ea693b9c3b374956c4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"debe4408e1494a2bb6623088d62b3afd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c4539ccc9674cc1855044c240cfc530":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3718bbba57304aa58e67e10fe7a2f521":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fec5b50871040149c04acea4b507e02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1c47e7dbecf4e0bb03f4203f6050ce4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbdfbf4316f94021a9e3b5aadf51371e","IPY_MODEL_864e2d8e3b52424a8fa5d0a14b7a2b88","IPY_MODEL_643552f7668447e8acbd26bebc7f048a"],"layout":"IPY_MODEL_b563cf828bd04604bf1281e04147d3aa"}},"bbdfbf4316f94021a9e3b5aadf51371e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f77f1503c2e548bb8a003ba0483e0dfd","placeholder":"‚Äã","style":"IPY_MODEL_b06cce3764c34375897b05d2922201f8","value":"config.json:‚Äá100%"}},"864e2d8e3b52424a8fa5d0a14b7a2b88":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bc2c17137714172803a3dc6314b530e","max":702,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c20c47f13714d848f317c485f1a3c8d","value":702}},"643552f7668447e8acbd26bebc7f048a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0dc99c4762547019ead7f7967357d2f","placeholder":"‚Äã","style":"IPY_MODEL_36c93eedef414e6f9c204da7d73fe2b4","value":"‚Äá702/702‚Äá[00:00&lt;00:00,‚Äá64.7kB/s]"}},"b563cf828bd04604bf1281e04147d3aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f77f1503c2e548bb8a003ba0483e0dfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b06cce3764c34375897b05d2922201f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bc2c17137714172803a3dc6314b530e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c20c47f13714d848f317c485f1a3c8d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0dc99c4762547019ead7f7967357d2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36c93eedef414e6f9c204da7d73fe2b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99069423ad5644448e681db25b4c8ef0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cdddd5490f6041d1807715b8b6bbc517","IPY_MODEL_fd66a8f5141f4983815142a6ed890149","IPY_MODEL_f5b0e5e2308144f5b40392e669edef6f"],"layout":"IPY_MODEL_6e569574465440b5a42183b0db6de8be"}},"cdddd5490f6041d1807715b8b6bbc517":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c144b4deb5784f68889ea54523fa29b0","placeholder":"‚Äã","style":"IPY_MODEL_029ce68c13674fc39fc723968f32998e","value":"spiece.model:‚Äá100%"}},"fd66a8f5141f4983815142a6ed890149":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_89fa7b5b92794da1984abb9f67c1ff62","max":4309802,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b258803f9fe64169867497bdf1bc9bc6","value":4309802}},"f5b0e5e2308144f5b40392e669edef6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddda41b0f56c48a9b4b767f49b6ada30","placeholder":"‚Äã","style":"IPY_MODEL_dd371a3bccdf479c8a528706ca12b893","value":"‚Äá4.31M/4.31M‚Äá[00:00&lt;00:00,‚Äá7.95MB/s]"}},"6e569574465440b5a42183b0db6de8be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c144b4deb5784f68889ea54523fa29b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"029ce68c13674fc39fc723968f32998e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89fa7b5b92794da1984abb9f67c1ff62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b258803f9fe64169867497bdf1bc9bc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ddda41b0f56c48a9b4b767f49b6ada30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd371a3bccdf479c8a528706ca12b893":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e81e236d4afb4e7f8e9e7ad131cbc314":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07410f62cef54eabad4a0be39f559909","IPY_MODEL_27f0633543ef47058b2892d7cf82b486","IPY_MODEL_3f5cc8a24c5a429ea200dfde1e9e56fd"],"layout":"IPY_MODEL_776e53199dbb493c919d3ce16c4784d8"}},"07410f62cef54eabad4a0be39f559909":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_675dc9efce4f429090d8fddcb7f7a854","placeholder":"‚Äã","style":"IPY_MODEL_96ab1b72270c413e8214016a1e1f7ebc","value":"special_tokens_map.json:‚Äá100%"}},"27f0633543ef47058b2892d7cf82b486":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43fc60412954449c945cc4e7ba83f904","max":65,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f77ccbe29314d638c76dcccdaf1059b","value":65}},"3f5cc8a24c5a429ea200dfde1e9e56fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfc8f63cc1274aad8a7ad8eec52e4dd8","placeholder":"‚Äã","style":"IPY_MODEL_349957e9361d4b82a36025836652633e","value":"‚Äá65.0/65.0‚Äá[00:00&lt;00:00,‚Äá6.17kB/s]"}},"776e53199dbb493c919d3ce16c4784d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"675dc9efce4f429090d8fddcb7f7a854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96ab1b72270c413e8214016a1e1f7ebc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43fc60412954449c945cc4e7ba83f904":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f77ccbe29314d638c76dcccdaf1059b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dfc8f63cc1274aad8a7ad8eec52e4dd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"349957e9361d4b82a36025836652633e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa51de248f8145a2946288b0ef805b0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12f8500374384a6ca01420be15d80565","IPY_MODEL_7c59a3557af24bfb9a6e231c0974c6e8","IPY_MODEL_71719307b9a949988e90429dc8dec7d0"],"layout":"IPY_MODEL_a09c776edc90400eb310d8630d40a41f"}},"12f8500374384a6ca01420be15d80565":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ec0757208fa42fbae86f73c79fdcc0b","placeholder":"‚Äã","style":"IPY_MODEL_378a80c71a174604a0ed10a80db9fd23","value":"Downloading‚Äábuilder‚Äáscript:‚Äá100%"}},"7c59a3557af24bfb9a6e231c0974c6e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cde20c5efce475f99766c8a34895a92","max":6270,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ee81008f9d0461085599310ad96e0d5","value":6270}},"71719307b9a949988e90429dc8dec7d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d162d6c2ea0d4ed1aa68511e9b2bebc5","placeholder":"‚Äã","style":"IPY_MODEL_dec0ccc23c51402899713c1a4d4b84d1","value":"‚Äá6.27k/6.27k‚Äá[00:00&lt;00:00,‚Äá486kB/s]"}},"a09c776edc90400eb310d8630d40a41f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ec0757208fa42fbae86f73c79fdcc0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"378a80c71a174604a0ed10a80db9fd23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cde20c5efce475f99766c8a34895a92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ee81008f9d0461085599310ad96e0d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d162d6c2ea0d4ed1aa68511e9b2bebc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dec0ccc23c51402899713c1a4d4b84d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}